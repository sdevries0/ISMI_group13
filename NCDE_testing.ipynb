{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdevries0/ISMI_group13/blob/main/NCDE_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aov2kYTYeGdE"
      },
      "outputs": [],
      "source": [
        "# import jax\n",
        "# from jax.lib import xla_bridge\n",
        "# print(xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c4DkaNTKvWe",
        "outputId": "136ba2bd-aa0b-40d6-d981-87d2527b8775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffrax in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: equinox>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from diffrax) (0.9.2)\n",
            "Requirement already satisfied: jax>=0.3.4 in /usr/local/lib/python3.8/dist-packages (from diffrax) (0.3.25)\n",
            "Requirement already satisfied: jaxtyping>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from equinox>=0.9.1->diffrax) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.4->diffrax) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.4->diffrax) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.4->diffrax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.4->diffrax) (3.3.0)\n",
            "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.5->equinox>=0.9.1->diffrax) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.8/dist-packages (0.1.4)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from optax) (0.1.5)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.8/dist-packages (from optax) (0.3.25)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install diffrax\n",
        "!pip install optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewoj__98v0cc",
        "outputId": "8a87f5b5-9f99-4b65-cab0-8654b34e8c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSPqoo9_K9E9"
      },
      "outputs": [],
      "source": [
        "from math import pi\n",
        "import numpy as np\n",
        "#from utils import plot_system, SinusoidalControlPath\n",
        "import matplotlib.pyplot as plt\n",
        "import diffrax as dfx\n",
        "import equinox as eqx  # https://github.com/patrick-kidger/equinox\n",
        "import jax.nn as jnn\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrandom\n",
        "import jax.scipy as jsp\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "import matplotlib.pyplot as plt\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "# from equinox.custom_types import Array\n",
        "import math\n",
        "from typing import Callable\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqtBEpqmO1SN"
      },
      "outputs": [],
      "source": [
        "# Define control path with multiple different functions. t is added to the resulting array. \n",
        "class MultiControlPath(dfx.AbstractPath):\n",
        "\n",
        "    C : int\n",
        "    phase: Callable\n",
        "    frequency: Callable\n",
        "\n",
        "    def __init__(self, phase, frequency, C = 2):\n",
        "      self.C = C\n",
        "      self.phase = phase\n",
        "      self.frequency = frequency\n",
        "\n",
        "    def evaluate(self, t0, t1=None, left=True):\n",
        "      del left\n",
        "      if t1 is not None:\n",
        "        return self.evaluate(t1) - self.evaluate(t0)\n",
        "      #Evaluate t0 and t1 for each sinoid control \n",
        "      controls_at_t = jnp.array([jnp.sin(self.phase[i] + self.frequency[i] * t0) for i in range(self.C)])\n",
        "      return jnp.append(t0, controls_at_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5AFgxbiK95B"
      },
      "outputs": [],
      "source": [
        "class CDE():\n",
        "    \n",
        "    f_state : Callable\n",
        "    f_obs : Callable\n",
        "\n",
        "    def __init__(self, f_state, f_obs = lambda x: x):\n",
        "        \"\"\"\n",
        "        params:\n",
        "            f_state: vector field; function dom_state -> dom_state x dom_ctrl\n",
        "            f_obs: linear readout (complete observability by default); function dom_ctrl -> dom_obs\n",
        "        \"\"\"\n",
        "        self.f_state = f_state\n",
        "        self.f_obs = f_obs\n",
        " \n",
        "    def __call__(self, ts, phase, frequency, init):\n",
        "        \"\"\"\n",
        "        Generates states at specified times ts given a control\n",
        " \n",
        "        params:\n",
        "            ts: time points\n",
        "            phase: phases used for control\n",
        "            frequency: frequencies used for control\n",
        "            init: initial state of the CDE \n",
        "        \"\"\"\n",
        "        #Create control\n",
        "        control = MultiControlPath(phase, frequency, frequency.shape[0])\n",
        "        system = dfx.ControlTerm(self.f_state, control).to_ode()\n",
        "        solver = dfx.Tsit5()\n",
        "        dt0=0.1\n",
        "        \n",
        "        #Solve differential equation\n",
        "        sol = dfx.diffeqsolve(\n",
        "            system,\n",
        "            solver,\n",
        "            ts[0],\n",
        "            ts[-1],\n",
        "            dt0,\n",
        "            y0=init,\n",
        "            stepsize_controller=dfx.ConstantStepSize(),\n",
        "            # stepsize_controller=dfx.PIDController(rtol=1e-3, atol=1e-6),\n",
        "            saveat=dfx.SaveAt(ts=ts),\n",
        "        )\n",
        "\n",
        "        # return phase, frequency, initial state, hidden states and observations\n",
        "        return jax.vmap(self.f_obs)(sol.ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r03g0s0-t-6"
      },
      "outputs": [],
      "source": [
        "class Dataloader():\n",
        "    def __init__(self, key, nr_batch, N, C, sd, dataset_size, ts):\n",
        "      assert dataset_size%nr_batch == 0\n",
        "      self.dataset_size = dataset_size\n",
        "      self.nr_batch = nr_batch\n",
        "      keys = jrandom.split(key, 3)\n",
        "      self.frequency = jrandom.uniform(keys[0], shape=(self.dataset_size, C), minval = 0.0, maxval = 1.0)\n",
        "      self.phase = jrandom.normal(keys[1], shape=(self.dataset_size, C))\n",
        "      init = sd*jrandom.normal(key, shape=(self.dataset_size, N))\n",
        "      self.dataset = jax.vmap(system, in_axes=[None, 0, 0, 0])(ts, self.phase, self.frequency, init)\n",
        "\n",
        "    def sample_observations(self, epoch):\n",
        "      start = (epoch*self.nr_batch)%self.dataset_size\n",
        "      end = start + self.nr_batch\n",
        "\n",
        "      return self.frequency[start:end], self.phase[start:end], self.dataset[start:end]\n",
        "      # new_key = jrandom.fold_in(self.key, epoch)\n",
        "      # indices = jrandom.randint(new_key,shape=(self.nr_batch,),minval=0,maxval=self.dataset_size)\n",
        "\n",
        "      # return self.frequency[indices], self.phase[indices], self.dataset[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8tRcPVXS02V"
      },
      "outputs": [],
      "source": [
        "class NeuralCDE(eqx.Module):\n",
        "    \n",
        "    f_state : Callable\n",
        "    f_init : Callable\n",
        "    f_obs : Callable\n",
        "    t0: int\n",
        "\n",
        "    def __init__(self, f_state, f_obs = lambda x: x, f_init = None, t0 = 0, **kwargs):\n",
        "        \"\"\"\n",
        "        params:\n",
        "            f_state: vector field; function dom_state -> dom_state x dom_ctrl\n",
        "            f_obs: linear readout (complete observability by default); function dom_state -> dom_obs\n",
        "            f_init: initial state; function dom_obs -> dom_state \n",
        "            t0: starting point of NCDE\n",
        "        \n",
        "        Each term can be either a fixed function (CDE) or a parameterized nonlinear function (neural CDE)\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.f_state = f_state\n",
        "        self.f_obs = f_obs\n",
        "        self.f_init = f_init\n",
        "        self.t0 = t0\n",
        "\n",
        "    def __call__(self, ts, phase, frequency, obs):\n",
        "        \"\"\"\n",
        "        Generates states at specified times ts given a control\n",
        "        The initial state is determined using another NCDE which receives the first observation and control\n",
        "        \"\"\"\n",
        "        #Create control\n",
        "        control = MultiControlPath(phase, frequency, frequency.shape[0])\n",
        "        system = dfx.ControlTerm(self.f_state, control).to_ode()\n",
        "\n",
        "        # #Determine initial state\n",
        "        y0 = self.f_init(ts[:self.t0], phase, frequency, obs)\n",
        "        # y0 = self.f_init(control.evaluate(ts[0]))\n",
        "\n",
        "        solver = dfx.Tsit5()\n",
        "        dt0=0.1\n",
        "\n",
        "        #Solve differential equation\n",
        "        sol = dfx.diffeqsolve(\n",
        "            system,\n",
        "            solver,\n",
        "            ts[self.t0],\n",
        "            ts[-1],\n",
        "            dt0,\n",
        "            y0,\n",
        "            stepsize_controller=dfx.ConstantStepSize(),\n",
        "            # stepsize_controller=dfx.PIDController(rtol=1e-3, atol=1e-6),\n",
        "            saveat=dfx.SaveAt(ts=ts[self.t0:]),\n",
        "        )\n",
        "\n",
        "        # return observations\n",
        "        return jax.vmap(self.f_obs)(sol.ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3wLaFutTA-A"
      },
      "outputs": [],
      "source": [
        "#Simple RNN that is used as state equation for the initialization NCDE\n",
        "class InitFunc(eqx.Module):\n",
        "    mlp: eqx.nn.MLP\n",
        "    ctrl_size: int\n",
        "    state_size: int\n",
        "\n",
        "    def __init__(self, state_size, ctrl_size, width_size, depth, *, key, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.ctrl_size = ctrl_size\n",
        "        self.state_size = state_size\n",
        "        self.mlp = eqx.nn.MLP(\n",
        "            in_size=state_size,\n",
        "            out_size=state_size * ctrl_size,\n",
        "            width_size=width_size,\n",
        "            depth=depth,\n",
        "            activation=jnn.softplus,\n",
        "            final_activation=jnn.tanh,\n",
        "            key=key,\n",
        "        )\n",
        "\n",
        "    def __call__(self, t, x, args):\n",
        "        return self.mlp(x).reshape(self.state_size, self.ctrl_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJhaVRNmJfrN"
      },
      "outputs": [],
      "source": [
        "class InitNeuralCDE(eqx.Module):\n",
        "    \n",
        "    f_control_state : InitFunc\n",
        "    f_obs_state: InitFunc\n",
        "    y0 : Callable\n",
        "    f_obs : Callable\n",
        "\n",
        "    def __init__(self, state_size, ctrl_size, M, width_size, depth, key = None, **kwargs):\n",
        "        \"\"\"\n",
        "        params:\n",
        "            f_state: vector field; function dom_state -> dom_state x dom_ctrl\n",
        "            f_obs: linear readout (complete observability by default); function dom_state -> dom_obs\n",
        "            f_init: initial state; function dom_obs -> dom_state \n",
        "            epsilon: added to the initial state to fix stability\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        control_key, obs_key, init_key = jrandom.split(key, 3)\n",
        "        self.f_control_state = InitFunc(state_size, ctrl_size, width_size, depth, key=control_key)\n",
        "        self.f_obs_state = InitFunc(state_size, M, width_size, depth, key=obs_key)\n",
        "        self.f_obs = lambda x: x\n",
        "        self.y0 = jrandom.normal(init_key, shape=(N,))\n",
        "\n",
        "    def __call__(self, ts, phase, frequency, obs):\n",
        "        \"\"\"\n",
        "        Generates states at specified times ts given a control\n",
        "        The initial state is determined using an MLP\n",
        "        \"\"\"\n",
        "        #Create control\n",
        "        control = MultiControlPath(phase, frequency, frequency.shape[0])\n",
        "        observation_control = dfx.LinearInterpolation(ts, obs)\n",
        "        s1 = dfx.ControlTerm(self.f_control_state, control).to_ode()\n",
        "        s2 = dfx.ControlTerm(self.f_obs_state, observation_control).to_ode()\n",
        "        system = dfx.MultiTerm(s1, s2)\n",
        "\n",
        "        #Determine initial state\n",
        "        # y0 = self.f_init(init + self.epsilon * jrandom.normal(key, shape=init.shape)) \n",
        "\n",
        "        solver = dfx.Tsit5() \n",
        "        dt0=0.1\n",
        "\n",
        "        #Solve differential equation\n",
        "        sol = dfx.diffeqsolve(\n",
        "            system,\n",
        "            solver,\n",
        "            ts[0],\n",
        "            ts[-1],\n",
        "            dt0,\n",
        "            self.y0,\n",
        "            stepsize_controller=dfx.ConstantStepSize(),\n",
        "            # stepsize_controller=dfx.PIDController(rtol=1e-3, atol=1e-6),\n",
        "            saveat=dfx.SaveAt(ts=ts),\n",
        "        )\n",
        "\n",
        "        # return observations\n",
        "        return jax.vmap(self.f_obs)(sol.ys[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pymgaNGB2ipE"
      },
      "outputs": [],
      "source": [
        "@eqx.filter_jit\n",
        "def mse_loss(model, ts, phase, frequency, obs, t0):\n",
        "    #Get predictions from NCDE\n",
        "    predictions = jax.vmap(model, in_axes=[None, 0, 0, 0])(ts, phase, frequency, obs[:,:t0])\n",
        "    #sum MSE loss over time points and take mean over batch dimension\n",
        "    return jnp.mean(jnp.sum(jnp.linalg.norm(predictions - obs[:,t0:], axis=2) ** 2, axis=1), axis = 0)\n",
        "\n",
        "def increase_update_initial(updates):\n",
        "    get_initial_leaves = lambda u: jax.tree_util.tree_leaves(u.f_init)\n",
        "    return eqx.tree_at(get_initial_leaves, updates, replace_fn=lambda x: x * 10)\n",
        "\n",
        "@eqx.filter_jit\n",
        "def make_step(ts, phase, frequency, model, obs, opt_state, grad_loss, optim, t0, block):\n",
        "    #Determine initial state\n",
        "    # init_states = jax.vmap(model.f_init,in_axes=[None, 0, 0, 0])(ts[:t0], phase, frequency, obs[:,:t0])\n",
        "    loss, grad = grad_loss(model, ts, phase, frequency, obs, t0)\n",
        "    updates, opt_state = optim.update(grad, opt_state)\n",
        "    updates = eqx.tree_at(lambda u: u.f_obs.W, updates, replace=updates.f_obs.W*block)\n",
        "    # updates = increase_update_initial(updates)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "\n",
        "    return loss, model, opt_state#, jnp.array(init_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDQVb2l2EJ53"
      },
      "outputs": [],
      "source": [
        "# Sigmoid firing rate\n",
        "# r = lambda x: 1/(1+jnp.exp(-x)) \n",
        "r = lambda x: jnp.tanh(x) #tanh\n",
        "# r = lambda x: (x>0) * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWy_sBskBfvf"
      },
      "outputs": [],
      "source": [
        "#RNN that models the states of neurons given input. Used as state equation for an NCDE\n",
        "class Func(eqx.Module):\n",
        "    \n",
        "    J: float\n",
        "    B: float\n",
        "    b: float\n",
        "    tau: float\n",
        "    N: int\n",
        "    C: int\n",
        "    \n",
        "    def __init__(self, keys, N, C, tau):\n",
        "        super().__init__()\n",
        "        keys = jrandom.split(key,3)\n",
        "        # self.J = jrandom.normal(keys[0], shape=(N,N))\n",
        "        self.J = 0.01*jnp.identity(N)\n",
        "        self.B = jrandom.normal(keys[1], shape=(N,C))\n",
        "        self.b = jrandom.normal(keys[2], shape=(N,))\n",
        "        self.tau = tau\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "\n",
        "    def __call__(self, t, x, args):\n",
        "      #Returns tau*x' = -x + Jr(x) + Bu + b\n",
        "      return jnp.concatenate(((-x+self.J@r(x) + self.b).reshape(self.N,1), self.B), axis = 1)\n",
        "      # return jnp.array([jnp.append(-x[i]+(self.J@r(x))[i] + self.b[i], jnp.array([self.B[i,j] for j in range(self.C)])) for i in range(self.N)])/self.tau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IYJmL75Y2Q3"
      },
      "outputs": [],
      "source": [
        "#Observation class used as the readout in the NCDE\n",
        "class Obs1(eqx.Module):\n",
        "    \n",
        "    W: float\n",
        "    \n",
        "    def __init__(self, key, N, M, block):\n",
        "        super().__init__()\n",
        "        self.W = jrandom.normal(key, shape=(M,N)) * block\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.W@r(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbxGXZwfbWKs"
      },
      "outputs": [],
      "source": [
        "def train_nn(key, N, C, M, system, time_points, nr_batch, tau, t0, block):\n",
        "  keys = jrandom.split(key, num=5)\n",
        "  new_key = keys[0]\n",
        "\n",
        "  #Initialize functions and MLPs for the initialization NCDE\n",
        "  # init_f_obs = lambda x: x\n",
        "\n",
        "  ctrl_size = C+1\n",
        "  state_size = N\n",
        "  width_size = 8\n",
        "  depth = 1\n",
        "\n",
        "  init_model = InitNeuralCDE(state_size, ctrl_size, M, width_size, depth, key=keys[1])\n",
        "\n",
        "  #State equation\n",
        "  f_state = Func(keys[2], N, C, tau)\n",
        "\n",
        "  #Observation function\n",
        "  f_obs = Obs1(keys[3], N, M, block)\n",
        "\n",
        "  #Use another NCDE as initialization function\n",
        "  f_init = init_model\n",
        "\n",
        "  # define model\n",
        "  model = NeuralCDE(f_state, f_obs, f_init, t0)\n",
        "\n",
        "  #Maximum number of epochs\n",
        "  epoch = 100000\n",
        "\n",
        "  #Threshold for convergence\n",
        "  threshold = 2000\n",
        "\n",
        "  #Initialize optimizer\n",
        "  lr = 1e-3\n",
        "  optim = optax.adam(lr)\n",
        "  \n",
        "  #SD used to sample initial states\n",
        "  sd = 1\n",
        "\n",
        "  grad_loss = eqx.filter_value_and_grad(mse_loss)\n",
        "\n",
        "  opt_state = optim.init(eqx.filter(model, eqx.is_array_like)) \n",
        "\n",
        "  #Initialize lists to save intermediate losses and weight values\n",
        "  losses = []\n",
        "  Js = [model.f_state.J]\n",
        "  Bs = [model.f_state.B]\n",
        "  bs = [model.f_state.b]\n",
        "  Ws = [model.f_obs.W]\n",
        "\n",
        "  #Parameters for convergence\n",
        "  best_loss = jnp.inf\n",
        "  last_loss = 0\n",
        "\n",
        "  dataloader = Dataloader(keys[4], nr_batch, N, C, sd, nr_batch*50, time_points)\n",
        "\n",
        "  for e in range(epoch):\n",
        "    try:\n",
        "      frequency, phase, obs = dataloader.sample_observations(e)\n",
        "      loss, model, opt_state = make_step(time_points, phase, frequency, model, obs, opt_state, grad_loss, optim, t0, block)\n",
        "      if (e % 1000) == 999:\n",
        "        print(r\"Currently at epoch: {}. The loss is: {}\".format(e+1,loss))\n",
        "\n",
        "      #Store intermediate loss and weight values\n",
        "      losses.append(loss)\n",
        "      Js.append(model.f_state.J)\n",
        "      Bs.append(model.f_state.B)\n",
        "      bs.append(model.f_state.b)\n",
        "      Ws.append(model.f_obs.W)\n",
        "\n",
        "      #New lowest loss has been reached\n",
        "      if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        last_loss = 0\n",
        "      #Current loss is higher than lowest loss\n",
        "      else:\n",
        "        last_loss += 1\n",
        "        #Loss did not decrease for a number of epochs in a row\n",
        "        if last_loss >= threshold and e>20000:\n",
        "              print(r\"The loss has converged on {} at epoch {}\".format(best_loss, e))\n",
        "              return losses, Js, Bs, bs, Ws\n",
        "\n",
        "    except:\n",
        "      # An error was thrown when the loss was too small\n",
        "      print(r\"The final loss is {} at epoch {}\".format(loss,e))\n",
        "      return losses[:-1], Js[:-1], Bs[:-1], bs, Ws[:-1]\n",
        "\n",
        "  return losses, Js, Bs, bs, Ws\n",
        "  #david sussillo, randall beer, jack galant, john pillow\n",
        "\n",
        "  #A suficient condition for a structure S to be ident$able\n",
        "  #is that the matrix of second-order partial derivatives with respect to the\n",
        "  #parameters, V_theta,theta , is positive definite for all theta in parameters. On structural identifiability\n",
        "\n",
        "  #kalman filter\n",
        "  #stability and equilibrium points\n",
        "  #The first 500 steps of gradient-based optimisation were performed on only the first 10 sample points of each time series (so that approximately the interval [0, 1] was considered instead)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2zrWj9z9htY"
      },
      "outputs": [],
      "source": [
        "def find_order(W_, W):\n",
        "  orders = np.zeros(W.shape, dtype=int)\n",
        "  for i in range(orders.shape[0]):\n",
        "    original = jnp.argsort(jnp.abs(W_[i]))\n",
        "    target = jnp.argsort(jnp.abs(W[i]))\n",
        "    for j in range(orders.shape[1]):\n",
        "      orders[i, original[j]] = target[j]\n",
        "\n",
        "  final_order = np.zeros(W.shape[1], dtype=int)\n",
        "  for j in range(orders.shape[1]):\n",
        "    values, counts = np.unique(orders[:,j], return_counts=True)\n",
        "    final_order[j] = values[jnp.argmax(counts)]\n",
        "  return jnp.array(final_order)\n",
        "\n",
        "def find_block_order(W_, W, groups):\n",
        "  counts = jnp.cumsum(groups, axis=0)\n",
        "  order = find_order(W_[:counts[0,1], :counts[0,0]], W[:counts[0,1], :counts[0,0]])\n",
        "  for i in range(1,counts.shape[0]):\n",
        "    block_order = find_order(W_[counts[i-1,1]:counts[i,1], counts[i-1,0]:counts[i,0]], W[counts[i-1,1]:counts[i,1], counts[i-1,0]:counts[i,0]])\n",
        "    order = jnp.append(order,block_order+counts[i-1,0])\n",
        "  print(order)\n",
        "  return order\n",
        "\n",
        "def moving_avg(losses):\n",
        "    mean_data = np.zeros(len(losses))\n",
        "    mean_data[0] = losses[0]\n",
        "    for i in range(1,len(losses)):\n",
        "        mean_data[i] = (losses[i] * 0.01 ) + (losses[i-1] * 0.99 )\n",
        "    return mean_data\n",
        "\n",
        "def plot_figures(losses, Js, Bs, bs, Ws, J, B, b, W, groups):\n",
        "  order = find_block_order(Ws[-1], W, groups)\n",
        "  fig, axes = plt.subplots(2, 3, figsize=(14, 10))\n",
        "  axes[0,0].plot(moving_avg(losses))\n",
        "  axes[0,0].set_title(\"Loss\")\n",
        "  axes[0,0].set(xlabel=\"Epoch\", ylabel=\"Log loss\")\n",
        "  axes[0,0].set_yscale('log')\n",
        "\n",
        "  help_J = jnp.abs(jnp.array([j[order] for j in J[order]]))\n",
        "  axes[0,1].plot([jnp.sum((help_J-jnp.abs(Js[i]))**2)/(J.shape[0]*J.shape[1]) for i in range(len(Js))])\n",
        "  axes[0,1].set_title(\"Mean squared error from estimated J to true J\")\n",
        "  axes[0,1].set(xlabel=\"Epoch\", ylabel=\"Mean squared error\")\n",
        "\n",
        "  help_B = jnp.abs(B[order])\n",
        "  axes[1,0].plot([jnp.sum((jnp.abs(Bs[i])-help_B)**2)/(B.shape[0]*B.shape[1]) for i in range(len(Bs))])\n",
        "  axes[1,0].set_title(\"Mean squared error from estimated B to true B\")\n",
        "  axes[1,0].set(xlabel=\"Epoch\", ylabel=\"Mean squared error\")\n",
        "\n",
        "  help_b = jnp.abs(b[order])\n",
        "  axes[1,1].plot([jnp.sum((jnp.abs(bs[i])-help_b)**2)/b.shape[0] for i in range(len(bs))])\n",
        "  axes[1,1].set_title(\"Mean squared error from estimated b to true b\")\n",
        "  axes[1,1].set(xlabel=\"Epoch\", ylabel=\"Mean squared error\")\n",
        "\n",
        "  help_W = jnp.abs(W[:,order])\n",
        "  axes[0,2].plot([jnp.sum((jnp.abs(Ws[i])-help_W)**2)/(W.shape[0]*W.shape[1]) for i in range(len(Ws))])\n",
        "  axes[0,2].set_title(\"Mean squared error from estimated W to true W\")\n",
        "  axes[0,2].set(xlabel=\"Epoch\", ylabel=\"Mean squared error\")\n",
        "\n",
        "    \n",
        "  # if J.shape[0] == 5:\n",
        "  #   axes[0,0].set_ylim(bottom=0)\n",
        "  #   axes[0,1].set_ylim(bottom=0, top=10)\n",
        "  #   axes[0,1].set_xlim(left=0, right=20000)\n",
        "  #   axes[1,0].set_ylim(bottom=0, top=10)\n",
        "  #   axes[1,0].set_xlim(left=0, right=20000)\n",
        "  #   axes[1,1].set_ylim(bottom=0, top=2)\n",
        "  #   axes[1,1].set_xlim(left=0, right=20000)\n",
        "  #   axes[0,2].set_ylim(bottom=0, top=10)\n",
        "  #   axes[0,2].set_xlim(left=0, right=20000)\n",
        "  # else:\n",
        "  #   axes[0,0].set_ylim(bottom=0)\n",
        "  #   axes[0,1].set_ylim(bottom=0, top=10)\n",
        "  #   axes[0,1].set_xlim(left=0, right=20000)\n",
        "  #   axes[1,0].set_ylim(bottom=0, top=10)\n",
        "  #   axes[1,0].set_xlim(left=0, right=20000)\n",
        "  #   axes[1,1].set_ylim(bottom=0, top=2)\n",
        "  #   axes[1,1].set_xlim(left=0, right=20000)\n",
        "  #   axes[0,2].set_ylim(bottom=0, top=10)\n",
        "  #   axes[0,2].set_xlim(left=0, right=20000)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  #RMSPROP instead of ADAM, no momentum, moving target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEVNE0AsowJ0",
        "outputId": "3bd1c487-e914-40e0-a841-a901228572a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently at epoch: 1000. The loss is: 505.3908996582031\n",
            "Currently at epoch: 2000. The loss is: 199.19320678710938\n",
            "Currently at epoch: 3000. The loss is: 166.9359893798828\n",
            "Currently at epoch: 4000. The loss is: 155.99000549316406\n",
            "Currently at epoch: 5000. The loss is: 136.4904022216797\n",
            "Currently at epoch: 6000. The loss is: 71.41743469238281\n",
            "Currently at epoch: 7000. The loss is: 52.659767150878906\n",
            "Currently at epoch: 8000. The loss is: 41.815467834472656\n",
            "Currently at epoch: 9000. The loss is: 27.86749267578125\n",
            "Currently at epoch: 10000. The loss is: 20.534526824951172\n",
            "Currently at epoch: 11000. The loss is: 17.237503051757812\n",
            "Currently at epoch: 12000. The loss is: 14.525548934936523\n",
            "Currently at epoch: 13000. The loss is: 12.671895980834961\n",
            "Currently at epoch: 14000. The loss is: 13.350332260131836\n",
            "Currently at epoch: 15000. The loss is: 8.616917610168457\n",
            "Currently at epoch: 16000. The loss is: 8.680686950683594\n",
            "Currently at epoch: 17000. The loss is: 7.372756004333496\n",
            "Currently at epoch: 18000. The loss is: 7.360935211181641\n"
          ]
        }
      ],
      "source": [
        "#Define number of neurons, control inputs and observations\n",
        "neuron_groups = jnp.array([[3,2],[2,2],[2,2]]) #N,M\n",
        "N = jnp.sum(neuron_groups[:,0]).item() #neurons\n",
        "C = 3 #control\n",
        "M = jnp.sum(neuron_groups[:,1]).item() #observations\n",
        "key = jrandom.PRNGKey(0)\n",
        "tau = 1 #time constant\n",
        "\n",
        "def block_diag(a,b):\n",
        "  result = np.zeros((a.shape[0]+b.shape[0],a.shape[1]+b.shape[1]))\n",
        "  result[:a.shape[0],:a.shape[1]] = a\n",
        "  result[a.shape[0]:,a.shape[1]:] = b\n",
        "  return jnp.array(result)\n",
        "\n",
        "keys = jrandom.split(key, num=4+neuron_groups.shape[0])\n",
        "key = keys[0]\n",
        "#Use Bernoulli matrices to induce sparsity\n",
        "p = 1.0 #sparsity\n",
        "J = jrandom.normal(keys[1], shape=(N,N)) * jrandom.bernoulli(keys[1], p=p, shape=(N,N)) \n",
        "B = jrandom.normal(keys[2], shape=(N,C)) * jrandom.bernoulli(keys[2], p=p, shape=(N,C)) \n",
        "b = jrandom.normal(keys[3], shape=(N,))\n",
        "# W = jrandom.normal(keys[4], shape=(M,N)) * jrandom.bernoulli(keys[4], p=p, shape=(M,N))\n",
        "W = jnp.empty([0,0])\n",
        "for i in range(neuron_groups.shape[0]):\n",
        "  neuron = neuron_groups[i]\n",
        "  W = block_diag(W, jrandom.normal(keys[4+i], shape=(neuron[1],neuron[0])) * jrandom.bernoulli(keys[4+i], p=p, shape=(neuron[1],neuron[0])))\n",
        "block = jnp.where(W==0,W,1)\n",
        "#State equation for the CDE\n",
        "f_state = lambda t, x, args: jnp.concatenate(((-x+J@r(x) + b).reshape(N,1), B), axis = 1)\n",
        "\n",
        "#Observation function for the CDE\n",
        "f_obs = lambda x : W@r(x)\n",
        "\n",
        "#Define CDE\n",
        "system = CDE(f_state, f_obs)\n",
        "\n",
        "#Time point that defines the starting point of the NCDE. The data before this point is used to predict the initial condition.\n",
        "t0 = 75\n",
        "\n",
        "#Sample path\n",
        "T = 500\n",
        "time_points = jnp.linspace(0, 8*pi, T)\n",
        "losses, Js, Bs, bs, Ws = train_nn(key, N, C, M, system, time_points, nr_batch = 64, tau=tau, t0=t0, block=block)\n",
        "plot_figures(losses, Js, Bs, bs, Ws, J, B, b, W, neuron_groups)\n",
        "\n",
        "#kleine weights, uniform weights, relu initialization network, mean 0, identity J, 0.01 identity, 1/N J\n",
        "#solve steps\n",
        "#random batches\n",
        "\n",
        "# lr: 5e-3, 1e-3, 5e-4\n",
        "# increased init lr\n",
        "# random vs batch\n",
        "# identity vs 0.01 identity vs 0.01 random weights vs uniform 1/N^2\n",
        "# initialization network relu vs tanh vs silu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEkOvub_rNcS"
      },
      "outputs": [],
      "source": [
        "order = find_block_order(Ws[-1],W, neuron_groups)\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14, 14))\n",
        "g1 = sns.heatmap(Js[-1],annot=True,ax=axes[0,0])\n",
        "g2 = sns.heatmap([j[order] for j in J[order]],annot=True,ax=axes[0,1])\n",
        "g3 = sns.heatmap(Bs[-1],annot=True,ax=axes[1,0])\n",
        "g4 = sns.heatmap(B[order],annot=True,ax=axes[1,1])\n",
        "g5 = sns.heatmap([bs[-1]],annot=True,ax=axes[2,0])\n",
        "g6 = sns.heatmap([b[order]],annot=True,ax=axes[2,1])\n",
        "g7 = sns.heatmap(Ws[-1],annot=True,ax=axes[3,0])\n",
        "g8 = sns.heatmap(W[:,order],annot=True,ax=axes[3,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1TXZpuMtgk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTgpv11JSp0w"
      },
      "outputs": [],
      "source": [
        "dictionary = {'losses':losses, 'Js':Js, 'Bs':Bs, 'bs':bs, 'Ws':Ws, 'True_J':J,'True_B':B,'True_b':b,'True_W':W}\n",
        "np.save(f'/content/drive/MyDrive/Thesis_Data/J_identity_0.01_fixed_batch.npy', dictionary) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hFEcGeJoMnV"
      },
      "outputs": [],
      "source": [
        "# read_dictionary = np.load('/content/drive/MyDrive/Thesis_Data/N_6_t0_50.npy',allow_pickle='TRUE').item()\n",
        "# plot_figures(losses, read_dictionary['Js'], read_dictionary['Bs'], read_dictionary['bs'], read_dictionary['Ws'], read_dictionary['True_J'], read_dictionary['True_B'], read_dictionary['True_b'], read_dictionary['True_W'], read_dictionary['x0s'], read_dictionary['x0'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}