{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdevries0/ISMI_group13/blob/main/Kopie_van_NSDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc5e6de-fd8f-4589-a5bc-8169cdc12ca1",
      "metadata": {
        "id": "0dc5e6de-fd8f-4589-a5bc-8169cdc12ca1"
      },
      "source": [
        "# Neural SDE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffrax\n",
        "!pip install optax"
      ],
      "metadata": {
        "id": "f5WgihPF68Rk",
        "outputId": "428c4cb2-41da-4d6d-a866-d78c60e82a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f5WgihPF68Rk",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffrax in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: jax>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from diffrax) (0.3.21)\n",
            "Requirement already satisfied: equinox>=0.5.4 in /usr/local/lib/python3.7/dist-packages (from diffrax) (0.8.0)\n",
            "Requirement already satisfied: jaxtyping>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from equinox>=0.5.4->diffrax) (0.2.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (4.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (3.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (0.8.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.4->diffrax) (1.7.3)\n",
            "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.7/dist-packages (from jaxtyping>=0.2.5->equinox>=0.5.4->diffrax) (2.13.3)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.4->diffrax) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.4->diffrax) (3.8.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.4.0)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.5)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.20+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.21)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TF_CPP_MIN_LOG_LEVEL=0"
      ],
      "metadata": {
        "id": "M0WZ7EH8WIyu"
      },
      "id": "M0WZ7EH8WIyu",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "350ecd31-c6f3-4cff-adbc-2f880c40f11a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-04T16:29:28.459951Z",
          "iopub.status.busy": "2022-02-04T16:29:28.458984Z",
          "iopub.status.idle": "2022-02-04T16:29:30.627192Z",
          "shell.execute_reply": "2022-02-04T16:29:30.626238Z"
        },
        "id": "350ecd31-c6f3-4cff-adbc-2f880c40f11a"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "from math import pi\n",
        "import diffrax as dfx\n",
        "import equinox as eqx  # https://github.com/patrick-kidger/equinox\n",
        "import jax\n",
        "import jax.nn as jnn\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrandom\n",
        "import matplotlib.pyplot as plt\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data"
      ],
      "metadata": {
        "id": "IUjaNz83I5JT"
      },
      "id": "IUjaNz83I5JT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid firing rate\n",
        "# r = lambda x: 1/(1+jnp.exp(-x)) \n",
        "r = lambda x: jnp.tanh(x) #tanh\n",
        "# r = lambda x: (x>0) * x"
      ],
      "metadata": {
        "id": "4k2g14vFAsBE"
      },
      "id": "4k2g14vFAsBE",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define control path with multiple different functions. t is added to the resulting array. \n",
        "class MultiControlPath(dfx.AbstractPath):\n",
        "    C: int\n",
        "    phase: Callable\n",
        "    frequency: Callable\n",
        "    noise: bool\n",
        "    key: jax.random.PRNGKey\n",
        "\n",
        "    def __init__(self, phase, frequency, key, C = 2):\n",
        "      self.C = C\n",
        "      self.phase = phase\n",
        "      self.frequency = frequency\n",
        "      if key is None:\n",
        "        self.noise = False\n",
        "        self.key = jrandom.PRNGKey(0)\n",
        "      else:\n",
        "        self.noise = True\n",
        "        self.key = key\n",
        "\n",
        "    def evaluate(self, t0, t1=None, left=True):\n",
        "      del left\n",
        "      if t1 is not None:\n",
        "        return self.evaluate(t1) - self.evaluate(t0)\n",
        "      #Evaluate t0 and t1 for each sinoid control \n",
        "      controls_at_t = jnp.array([jnp.sin(self.phase[i] + self.frequency[i] * t0) for i in range(self.C)])\n",
        "      if self.noise:\n",
        "        #Fix keys\n",
        "        new_key = jax.random.fold_in(key, t0)\n",
        "        dw = jrandom.normal(new_key, shape=(1,))\n",
        "        return jnp.append(jnp.append(t0, controls_at_t), dw)\n",
        "      else:\n",
        "        return jnp.append(t0, controls_at_t)"
      ],
      "metadata": {
        "id": "Tsy4qNEJIyvU"
      },
      "id": "Tsy4qNEJIyvU",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CDE():\n",
        "    \n",
        "    f_state : Callable\n",
        "    f_obs : Callable\n",
        "\n",
        "    def __init__(self, f_state, f_obs = lambda x: x):\n",
        "        \"\"\"\n",
        "        params:\n",
        "            f_state: vector field; function dom_state -> dom_state x dom_ctrl\n",
        "            f_obs: linear readout (complete observability by default); function dom_ctrl -> dom_obs\n",
        "        \"\"\"\n",
        "        self.f_state = f_state\n",
        "        self.f_obs = f_obs\n",
        " \n",
        "    def __call__(self, ts, phase, frequency, init):\n",
        "        \"\"\"\n",
        "        Generates states at specified times ts given a control\n",
        " \n",
        "        params:\n",
        "            ts: time points\n",
        "            phase: phases used for control\n",
        "            frequency: frequencies used for control\n",
        "            init: initial state of the CDE \n",
        "        \"\"\"\n",
        "        #Create control\n",
        "        control = MultiControlPath(phase, frequency, None, frequency.shape[0])\n",
        "        system = dfx.ControlTerm(self.f_state, control).to_ode()\n",
        "        solver = dfx.Tsit5()\n",
        "        dt0=0.01\n",
        "        \n",
        "        #Solve differential equation\n",
        "        sol = dfx.diffeqsolve(\n",
        "            system,\n",
        "            solver,\n",
        "            ts[0],\n",
        "            ts[-1],\n",
        "            dt0,\n",
        "            y0=init,\n",
        "            stepsize_controller=dfx.PIDController(rtol=1e-3, atol=1e-6),\n",
        "            saveat=dfx.SaveAt(ts=ts)\n",
        "        )\n",
        "\n",
        "        # return phase, frequency, initial state, hidden states and observations\n",
        "        return phase, frequency, init, sol.ys, jax.vmap(self.f_obs)(sol.ys)"
      ],
      "metadata": {
        "id": "uKZkaM18IX0i"
      },
      "id": "uKZkaM18IX0i",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use a CDE as a data generator\n",
        "def dataloader(system, ts, nr_batch, keys, N=1, C=1, sd=1.0):\n",
        "    #Sample initial states\n",
        "    init = sd*jrandom.normal(keys[1], shape=(nr_batch, N))\n",
        "\n",
        "    #Sample frequencies and phases\n",
        "    frequency = jrandom.uniform(keys[2], shape=(nr_batch, C), minval = 0.0, maxval = 3.0)\n",
        "    phase = jrandom.normal(keys[3], shape=(nr_batch, C))\n",
        "\n",
        "    #Generate data from the CDE\n",
        "    return jax.vmap(system, in_axes=[None, 0, 0, 0])(ts, phase, frequency, init)"
      ],
      "metadata": {
        "id": "eX2_fBbUJGFn"
      },
      "id": "eX2_fBbUJGFn",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NSDE+NCDE"
      ],
      "metadata": {
        "id": "8e1baDUlI8E0"
      },
      "id": "8e1baDUlI8E0"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "df41f97b-8b00-49c4-84fe-b35f340b7be5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-04T16:29:30.632152Z",
          "iopub.status.busy": "2022-02-04T16:29:30.631233Z",
          "iopub.status.idle": "2022-02-04T16:29:30.633125Z",
          "shell.execute_reply": "2022-02-04T16:29:30.633856Z"
        },
        "id": "df41f97b-8b00-49c4-84fe-b35f340b7be5"
      },
      "outputs": [],
      "source": [
        "def lipswish(x):\n",
        "    return 0.909 * jnn.silu(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN that models the states of neurons given input. Used as state equation for an NCDE\n",
        "class NeuralSystem(eqx.Module):\n",
        "    \n",
        "    J: float\n",
        "    B: float\n",
        "    b: float\n",
        "    tau: float\n",
        "    N: int\n",
        "    C: int\n",
        "    noise_component: eqx.nn.MLP\n",
        "    noise_size: int\n",
        "    \n",
        "    def __init__(self, keys, N, C, noise_size, tau):\n",
        "        super().__init__()\n",
        "        self.J = jrandom.normal(keys[0], shape=(N,N))\n",
        "        self.B = jrandom.normal(keys[1], shape=(N,C))\n",
        "        self.b = jrandom.normal(keys[2], shape=(N,))\n",
        "        self.tau = tau\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "        self.noise_size = noise_size\n",
        "        self.noise_component = eqx.nn.MLP(in_size=N, out_size=N * noise_size, width_size=8, depth=1, activation=jnn.tanh, final_activation=jnn.tanh, key=keys[3],)\n",
        "\n",
        "    def __call__(self, t, x, args):\n",
        "      #Returns tau*x' = -x + Jr(x) + Bu + b\n",
        "      return jnp.concatenate((\n",
        "          jnp.concatenate((jnp.array([-x[i]+(self.J@r(x))[i] + self.b[i] for i in range(self.N)]).reshape(self.N,1), jnp.array([[self.B[i,j] for j in range(self.C)] for i in range(self.N)])),axis=1),\n",
        "          self.noise_component(x).reshape(N,self.noise_size)),axis=1)/self.tau\n"
      ],
      "metadata": {
        "id": "V7JMJty--eIJ"
      },
      "id": "V7JMJty--eIJ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorField(eqx.Module):\n",
        "    scale: Union[int, jnp.ndarray]\n",
        "    mlp: eqx.nn.MLP\n",
        "\n",
        "    def __init__(self, hidden_size, width_size, depth, scale, *, key, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        scale_key, mlp_key = jrandom.split(key)\n",
        "        if scale:\n",
        "            self.scale = jrandom.uniform(\n",
        "                scale_key, (hidden_size,), minval=0.9, maxval=1.1\n",
        "            )\n",
        "        else:\n",
        "            self.scale = 1\n",
        "        self.mlp = eqx.nn.MLP(in_size=hidden_size, out_size=hidden_size, width_size=width_size, depth=depth, activation=jnn.tanh, final_activation=jnn.tanh, key=mlp_key,)\n",
        "\n",
        "    def __call__(self, t, y, args):\n",
        "        return self.scale * self.mlp(y)\n",
        "\n",
        "\n",
        "# class VectorField(eqx.Module):\n",
        "#     scale: Union[int, jnp.ndarray]\n",
        "#     mlp: eqx.nn.MLP\n",
        "\n",
        "#     def __init__(self, hidden_size, control_size, noise_size, width_size, depth, scale, *, key, **kwargs):\n",
        "#         super().__init__(**kwargs)\n",
        "#         scale_key, mlp_key = jrandom.split(key)\n",
        "#         self.mlp = eqx.nn.MLP(in_size=hidden_size, out_size=hidden_size*(control_size+1), width_size=width_size, depth=depth, activation=jnn.tanh, final_activation=jnn.tanh, key=mlp_key,)\n",
        "#         self.noise_component = eqx.nn.MLP(in_size=hidden_size, out_size=hidden_size*noise_size, width_size=width_size, depth=depth, activation=jnn.tanh, final_activation=jnn.tanh, key=mlp_key,)\n",
        "#         self.noise_size = noise_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.control_size = control_size\n",
        "\n",
        "\n",
        "#     def __call__(self, t, x, args):\n",
        "#         return jnp.concatenate((self.mlp(x).reshape(self.hidden_size,self.control_size), self.noise_component(x).reshape(self.hidden_size, self.noise_size)),axis=1)"
      ],
      "metadata": {
        "id": "BmzNZPjYFW14"
      },
      "id": "BmzNZPjYFW14",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ControlledVectorField(eqx.Module):\n",
        "    scale: Union[int, jnp.ndarray]\n",
        "    mlp: eqx.nn.MLP\n",
        "    noise_size: int\n",
        "    hidden_size: int\n",
        "\n",
        "    def __init__(\n",
        "        self, noise_size, hidden_size, width_size, depth, scale, *, key, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        scale_key, mlp_key = jrandom.split(key)\n",
        "        if scale:\n",
        "            self.scale = jrandom.uniform(scale_key, (hidden_size, noise_size), minval=0.9, maxval=1.1)\n",
        "        else:\n",
        "            self.scale = 1\n",
        "        self.mlp = eqx.nn.MLP(in_size=hidden_size, out_size=hidden_size * noise_size, width_size=width_size, depth=depth, activation=jnn.tanh, final_activation=jnn.tanh, key=mlp_key,)\n",
        "        self.noise_size = noise_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def __call__(self, t, y, args):\n",
        "        return self.scale * self.mlp(y).reshape(self.hidden_size, self.noise_size)"
      ],
      "metadata": {
        "id": "hrqC7k7W-rtN"
      },
      "id": "hrqC7k7W-rtN",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Observation class used as the readout in the NCDE\n",
        "class Readout(eqx.Module):\n",
        "    \n",
        "    W: float\n",
        "    \n",
        "    def __init__(self, key, N, M):\n",
        "        super().__init__()\n",
        "        self.W = jrandom.normal(key, shape=(M,N))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.W@r(x)"
      ],
      "metadata": {
        "id": "-C8MKIlN_Lhh"
      },
      "id": "-C8MKIlN_Lhh",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralSDE(eqx.Module):\n",
        "    initial: eqx.nn.MLP\n",
        "    drift: NeuralSystem  # drift\n",
        "    # diffusion: ControlledVectorField  # diffusion\n",
        "    readout: Readout\n",
        "    V: int #initial noise size\n",
        "    C: int\n",
        "    noise_size: int #noise size\n",
        "\n",
        "    def __init__(self, V, noise_size, width_size, depth, key, N, C, M, tau, **kwargs,):\n",
        "      super().__init__(**kwargs)\n",
        "      keys = jrandom.split(key, 7)\n",
        "\n",
        "      self.initial = eqx.nn.MLP(V, N, width_size, depth, key=keys[0])\n",
        "      self.drift = NeuralSystem(keys[1:5], N, C, noise_size, tau)\n",
        "      # self.diffusion = ControlledVectorField(noise_size, N, width_size, depth, scale=True, key=keys[5])\n",
        "      self.readout = Readout(keys[6], N, M)\n",
        "\n",
        "      self.V = V\n",
        "      self.C = C\n",
        "      self.noise_size = noise_size\n",
        "\n",
        "    def __call__(self, ts, phase, frequency, key):\n",
        "      t0 = ts[0]\n",
        "      t1 = ts[-1]\n",
        "      dt0 = 1.0\n",
        "      init_key, bm_key = jrandom.split(key, 2)\n",
        "      init = jrandom.normal(init_key, (self.V,))\n",
        "      control = MultiControlPath(phase, frequency, bm_key, self.C)\n",
        "      # control = dfx.VirtualBrownianTree(t0=t0, t1=t1, tol=dt0 , shape=(self.noise_size,), key=bm_key)\n",
        "      # drift = dfx.ODETerm(self.drift)  # Drift term\n",
        "      system = dfx.ControlTerm(self.drift, control).to_ode()  # Diffusion term\n",
        "      # terms = dfx.MultiTerm(drift, diffusion)\n",
        "      # ReversibleHeun is a cheap choice of SDE solver. We could also use Euler etc.\n",
        "      solver = dfx.ReversibleHeun()\n",
        "      y0 = self.initial(init)\n",
        "      saveat = dfx.SaveAt(ts=ts)\n",
        "      # We happen to know from our dataset that we're not going to take many steps.\n",
        "      # Specifying a smallest-possible upper bound speeds things up.\n",
        "      sol = dfx.diffeqsolve(\n",
        "          system, solver, t0, t1, dt0, y0, saveat=saveat, max_steps=128\n",
        "      )\n",
        "      return jax.vmap(self.readout)(sol.ys)"
      ],
      "metadata": {
        "id": "gPOw7I0C-75M"
      },
      "id": "gPOw7I0C-75M",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralCDE(eqx.Module):\n",
        "    initial: eqx.nn.MLP\n",
        "    drift: VectorField\n",
        "    diffusion: ControlledVectorField\n",
        "    readout: eqx.nn.Linear\n",
        "\n",
        "    def __init__(self, width_size, depth, key, N, C, M, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        initial_key, vf_key, cvf_key, readout_key = jrandom.split(key, 4)\n",
        "\n",
        "        self.initial = eqx.nn.MLP(M, N, width_size, depth, key=initial_key)\n",
        "        self.drift = VectorField(N, width_size, depth, scale=False, key=vf_key)\n",
        "        self.diffusion = ControlledVectorField(M, N, width_size, depth, scale=False, key=cvf_key)\n",
        "        self.readout = eqx.nn.Linear(N, 1, key=readout_key)\n",
        "\n",
        "    def __call__(self, ts, ys):\n",
        "        # Interpolate data into a continuous path.\n",
        "        ys = dfx.linear_interpolation(ts, ys, replace_nans_at_start=0.0, fill_forward_nans_at_end=True)\n",
        "        init = ys[0]\n",
        "        control = dfx.LinearInterpolation(ts, ys)\n",
        "        drift = dfx.ODETerm(self.drift)\n",
        "        diffusion = dfx.ControlTerm(self.diffusion, control).to_ode()\n",
        "        terms = dfx.MultiTerm(drift, diffusion)\n",
        "        solver = dfx.ReversibleHeun()\n",
        "        t0 = ts[0]\n",
        "        t1 = ts[-1]\n",
        "        dt0 = 1.0\n",
        "        y0 = self.initial(init)\n",
        "        # Have the discriminator produce an output at both `t0` *and* `t1`.\n",
        "        # The output at `t0` has only seen the initial point of a sample. This gives\n",
        "        # additional supervision to the distribution learnt for the initial condition.\n",
        "        # The output at `t1` has seen the entire path of a sample. This is needed to\n",
        "        # actually learn the evolving trajectory.\n",
        "        saveat = dfx.SaveAt(ts=ts)\n",
        "        sol = dfx.diffeqsolve(\n",
        "            diffusion, solver, t0, t1, dt0, y0, saveat=saveat, max_steps=128\n",
        "        )\n",
        "        loc = jnp.array([0,-1])\n",
        "        return jax.vmap(self.readout)(sol.ys[loc])\n",
        "\n",
        "    @eqx.filter_jit\n",
        "    def clip_weights(self):\n",
        "        leaves, treedef = jax.tree_util.tree_flatten(\n",
        "            self, is_leaf=lambda x: isinstance(x, eqx.nn.Linear)\n",
        "        )\n",
        "        new_leaves = []\n",
        "        for leaf in leaves:\n",
        "            if isinstance(leaf, eqx.nn.Linear):\n",
        "                lim = 1 / leaf.out_features\n",
        "                leaf = eqx.tree_at(\n",
        "                    lambda x: x.weight, leaf, leaf.weight.clip(-lim, lim)\n",
        "                )\n",
        "            new_leaves.append(leaf)\n",
        "        return jax.tree_util.tree_unflatten(treedef, new_leaves)"
      ],
      "metadata": {
        "id": "zXHIEHxkChBS"
      },
      "id": "zXHIEHxkChBS",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Losses"
      ],
      "metadata": {
        "id": "SrG26GFoK__D"
      },
      "id": "SrG26GFoK__D"
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def GAN_loss(generator, discriminator, ts_i, ys_i, phase, frequency, keys, step=0):\n",
        "    fake_ys_i = jax.vmap(generator, in_axes=[None, 0, 0, 0])(ts_i, phase, frequency, keys)\n",
        "    real_score = jax.vmap(discriminator, in_axes=[None, 0])(ts_i, ys_i)\n",
        "    fake_score = jax.vmap(discriminator, in_axes=[None, 0])(ts_i, fake_ys_i)\n",
        "    return jnp.mean(real_score - fake_score)\n",
        "\n",
        "@eqx.filter_grad\n",
        "def grad_loss(g_d, ts_i, ys_i, phase, frequency, keys, step):\n",
        "    generator, discriminator = g_d\n",
        "    return GAN_loss(generator, discriminator, ts_i, ys_i, phase, frequency, keys, step)"
      ],
      "metadata": {
        "id": "XH7LtThuK_cF"
      },
      "id": "XH7LtThuK_cF",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def make_step(generator, discriminator, g_opt_state, d_opt_state, g_optim, d_optim, ts_i, ys_i, phase, frequency, keys, step):\n",
        "    g_grad, d_grad = grad_loss((generator, discriminator), ts_i, ys_i, phase, frequency, keys, step)\n",
        "    g_updates, g_opt_state = g_optim.update(g_grad, g_opt_state)\n",
        "    d_updates, d_opt_state = d_optim.update(d_grad, d_opt_state)\n",
        "    # g_updates = increase_update_initial(g_updates)\n",
        "    # d_updates = increase_update_initial(d_updates)\n",
        "    generator = eqx.apply_updates(generator, g_updates)\n",
        "    discriminator = eqx.apply_updates(discriminator, d_updates)\n",
        "    discriminator = discriminator.clip_weights()\n",
        "    return generator, discriminator, g_opt_state, d_opt_state"
      ],
      "metadata": {
        "id": "cM0iY4HWMeJA"
      },
      "id": "cM0iY4HWMeJA",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main part"
      ],
      "metadata": {
        "id": "d8xEkenlI_Xe"
      },
      "id": "d8xEkenlI_Xe"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn(key, N, C, M, system, time_points, nr_batch, tau):\n",
        "  keys = jrandom.split(key, num=7)\n",
        "  new_key = keys[0]\n",
        "\n",
        "  # define model\n",
        "  V = 2\n",
        "  noise_size = 1\n",
        "  generator = NeuralSDE(V, noise_size, 8, 1, key, N, C, M, tau)\n",
        "  discriminator = NeuralCDE(8, 1, key, N, C, M)\n",
        "\n",
        "  #Maximum number of epochs\n",
        "  epoch = 1000\n",
        "\n",
        "  #Threshold for convergence\n",
        "  threshold = 500\n",
        "  \n",
        "  #SD used to sample initial states\n",
        "  sd = 1e-5\n",
        "\n",
        "  # grad_loss = eqx.filter_value_and_grad(GAN_loss)\n",
        "\n",
        "  generator_lr = 1e-3\n",
        "  discriminator_lr = 5e-3\n",
        "\n",
        "  g_optim = optax.rmsprop(generator_lr)\n",
        "  d_optim = optax.rmsprop(-discriminator_lr)\n",
        "  g_opt_state = g_optim.init(eqx.filter(generator, eqx.is_inexact_array))\n",
        "  d_opt_state = d_optim.init(eqx.filter(discriminator, eqx.is_inexact_array))\n",
        "\n",
        "  #Initialize lists to save intermediate losses and weight values\n",
        "  g_losses = []\n",
        "  d_losses = []\n",
        "  Js = [generator.drift.J]\n",
        "  Bs = [generator.drift.B]\n",
        "  bs = [generator.drift.b]\n",
        "  Ws = [generator.readout.W]\n",
        "  \n",
        "  keys = jrandom.split(new_key, num=4)\n",
        "  new_key = keys[0]\n",
        "\n",
        "  #Parameters for convergence\n",
        "  best_loss = jnp.inf\n",
        "  last_loss = 0\n",
        "\n",
        "  #Generate data consisting of phases and frequencies for control, initial and hidden states and observations\n",
        "  phase, frequency, init, state, obs = dataloader(system, time_points, nr_batch=nr_batch, keys=keys[1:], N=N, C=C, sd=sd)\n",
        "\n",
        "  for e in range(epoch):\n",
        "    new_keys = jrandom.split(new_key, num=nr_batch+1)\n",
        "    key = new_keys[0]\n",
        "    # try:\n",
        "    generator, discriminator, g_opt_state, d_opt_state = make_step(generator, discriminator, g_opt_state, d_opt_state, g_optim, d_optim, time_points, obs, phase, frequency, new_keys[1:], e)\n",
        "\n",
        "    if (e % 50) == 49:\n",
        "      print(e)\n",
        "      # print(r\"Currently at epoch: {}. The generator loss is: {} and the discriminator loss is: {}\".format(e+1, g_loss, d_loss))\n",
        "\n",
        "    #Store intermediate loss and weight values\n",
        "    # g_losses.append(g_loss)\n",
        "    # d_losses.append(d_loss)\n",
        "    Js.append(generator.drift.J)\n",
        "    Bs.append(generator.drift.B)\n",
        "    bs.append(generator.drift.b)\n",
        "    Ws.append(generator.readout.W)\n",
        "\n",
        "    # #New lowest loss has been reached\n",
        "    # if g_loss < best_loss:\n",
        "    #   best_loss = g_loss\n",
        "    #   last_loss = 0\n",
        "    # #Current loss is higher than lowest loss\n",
        "    # else:\n",
        "    #   last_loss += 1\n",
        "    #   #Loss did not decrease for a number of epochs in a row\n",
        "    #   if last_loss >= threshold:\n",
        "    #         print(r\"The loss has converged on {} at epoch {}\".format(best_loss, e))\n",
        "    #         return g_losses, d_losses, Js, Bs, bs, Ws\n",
        "\n",
        "    # except:\n",
        "    #   # An error was thrown when the loss was too small\n",
        "    #   print(r\"The final loss is {} at epoch {}\".format(loss,epoch))\n",
        "    #   return losses[:-1], Js[:-1], Bs[:-1], bs, Ws[:-1] #HIER\n",
        "    \n",
        "  return g_losses, d_losses, Js, Bs, bs, Ws"
      ],
      "metadata": {
        "id": "GbKBuIEVJQzm"
      },
      "id": "GbKBuIEVJQzm",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define number of neurons, control inputs and observations\n",
        "N = 2 #neurons\n",
        "C = 1 #control\n",
        "M = 1 #observations\n",
        "key = jrandom.PRNGKey(0)\n",
        "tau = 1 #time constant\n",
        "keys = jrandom.split(key, num=5)\n",
        "key = keys[0]\n",
        "\n",
        "#Use Bernoulli matrices to induce sparsity\n",
        "p = 1.0 #sparsity\n",
        "J = jrandom.normal(keys[1], shape=(N,N)) * jrandom.bernoulli(keys[1], p=p, shape=(N,N)) \n",
        "B = jrandom.normal(keys[2], shape=(N,C)) * jrandom.bernoulli(keys[2], p=p, shape=(N,C)) \n",
        "b = jrandom.normal(keys[3], shape=(N,))\n",
        "W = jrandom.normal(keys[4], shape=(M,N)) * jrandom.bernoulli(keys[4], p=p, shape=(M,N)) \n",
        "\n",
        "#State equation for the CDE\n",
        "f_state = lambda t, x, args: jnp.array([jnp.append(-x[i]+(J@r(x))[i] + b[i],jnp.array([B[i,j] for j in range(C)])) for i in range(N)])\n",
        "\n",
        "#Observation function for the CDE\n",
        "f_obs = lambda x : W@r(x)\n",
        "\n",
        "#Define CDE\n",
        "system = CDE(f_state, f_obs)\n",
        "\n",
        "#Sample path\n",
        "T = 100\n",
        "time_points = jnp.linspace(0, 2*pi, T)\n",
        "\n",
        "g_losses, d_losses, Js, Bs, bs, Ws = train_nn(key, N, C, M, system, time_points, nr_batch = 2, tau=tau)\n",
        "# plot_figures(losses, Js, Bs, bs, Ws, J, B, b, W)"
      ],
      "metadata": {
        "id": "4uylZPvUIMDe",
        "outputId": "9679db15-3cc7-428d-969b-ca26d5953a37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4uylZPvUIMDe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jax0227",
      "language": "python",
      "name": "jax0227"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}